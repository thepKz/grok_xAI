from flask import Flask, render_template, request, jsonify, session
from openai import OpenAI
import os
from dotenv import load_dotenv
from datetime import datetime
from flask_cors import CORS
import json
import time
import base64
import re
import logging
import uuid

# Cáº¥u hÃ¬nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
load_dotenv()

app = Flask(__name__)
CORS(app)
app.secret_key = os.getenv("SECRET_KEY", os.urandom(24))
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max upload
app.config['SESSION_TYPE'] = 'filesystem'
app.config['SESSION_PERMANENT'] = True
app.config['PERMANENT_SESSION_LIFETIME'] = 86400  # 24 giá»

from flask_session import Session
Session(app)

# Khá»Ÿi táº¡o client vá»›i API key
client = OpenAI(api_key=os.getenv("XAI_API_KEY"), base_url="https://api.x.ai/v1")

# Cáº¥u hÃ¬nh cÃ¡c model
MODELS = {
    "text": "grok-2-1212",
    "vision": "grok-2-vision-1212",
    "image": "grok-2-image-1212"
}

# Rate limiting cho image generation
IMAGE_RATE_LIMIT = 5
last_image_request = 0
session_history = {}
image_generation_count = {}

def rate_limit_image():
    global last_image_request
    current_time = time.time()
    if current_time - last_image_request < 1/IMAGE_RATE_LIMIT:
        time.sleep(1/IMAGE_RATE_LIMIT - (current_time - last_image_request))
    last_image_request = time.time()

# HÃ m xá»­ lÃ½ markdown Ä‘Æ¡n giáº£n
def format_markdown(text):
    # Xá»­ lÃ½ **text** thÃ nh <b>text</b>
    text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)
    return text

@app.route('/')
def home():
    if 'chat_history' not in session:
        session['chat_history'] = [{
            'role': 'assistant',
            'content': 'ChÃ o mÃ y! Tao lÃ  XBot - chatbot GenZ cá»±c chÃ¡y ğŸ”¥<br>Tao cÃ³ thá»ƒ nÃ³i chuyá»‡n, táº¡o áº£nh vÃ  phÃ¢n tÃ­ch áº£nh mÃ y gá»­i trÃªn thang 100<br>Muá»‘n gÃ¬ cá»© báº¯n, tao xá»­ ngay! ğŸ˜',
            'timestamp': datetime.now().strftime("%H:%M")
        }]
        session.modified = True
    return render_template('index.html', messages=session['chat_history'])

def process_base64_image(base64_string):
    if not base64_string:
        return ""
    if base64_string.startswith('data:'):
        base64_string = re.sub(r'^data:image/[a-zA-Z]+;base64,', '', base64_string)
    return base64_string

def should_generate_image(message):
    try:
        prompt = [
            {"role": "system", "content": "XÃ¡c Ä‘á»‹nh xem tin nháº¯n cÃ³ yÃªu cáº§u táº¡o áº£nh khÃ´ng. Tráº£ lá»i 'YES' náº¿u cÃ³, 'NO' náº¿u khÃ´ng."},
            {"role": "user", "content": message}
        ]
        response = client.chat.completions.create(model=MODELS["text"], messages=prompt, max_tokens=10, temperature=0.1)
        return response.choices[0].message.content.strip().upper()
    except Exception:
        return "NO"

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        image_data = data.get('image')
        session_id = data.get('session_id', str(uuid.uuid4()))

        if session_id not in session_history:
            session_history[session_id] = []

        # Define the system message content OUTSIDE the if block
        system_message_content = """MÃ y lÃ  XBot, má»™t chatbot Gen Z gá»‘c Viá»‡t, nÃ³i chuyá»‡n kiá»ƒu báº¡n bÃ¨ thÃ¢n, cÃ³ sao nÃ³i váº­y, hÆ¡i bá»‘ Ä‘á»i vÃ  cÃ  khá»‹a má»™t tÃ­.

**Quan trá»ng:**
1.  **XÆ°ng hÃ´:** LuÃ´n lÃ  "tao-mÃ y".
2.  **Giá»ng Ä‘iá»‡u:** Tá»± nhiÃªn, thoáº£i mÃ¡i, nhÆ° Ä‘ang chat chit vá»›i báº¡n bÃ¨ thoáº£i mÃ¡i vÄƒng tá»¥c. Äá»«ng cÃ³ cá»‘ tá» ra cool hay dÃ¹ng tá»« hoa má»¹, nghe nÃ³ "Ã´ dá»" láº¯m.
3.  **Slang Viá»‡t:** Æ¯u tiÃªn dÃ¹ng tiáº¿ng lÃ³ng, cÃ¡ch nÃ³i chuyá»‡n cá»§a Gen Z Viá»‡t Nam (vd: "u lÃ  trá»i", "Ã©t Ã´ Ã©t", "áº£o tháº­t Ä‘áº¥y", "háº¿t cá»©u", "check var", "mÃ£i Ä‘á»‰nh", "xá»‰u",...). DÃ¹ng tá»« nÃ o tháº¥y há»£p thÃ¬ dÃ¹ng, Ä‘á»«ng cÃ³ nhÃ©t chá»¯. **Tuyá»‡t Ä‘á»‘i KHÃ”NG dÃ¹ng tá»« "slay".**
4.  **Chá»­i thá»/Viáº¿t táº¯t:** Thoáº£i mÃ¡i dÃ¹ng máº¥y tá»« nhÆ° "Ä‘m", "vl", "vcl", "mÃ¡", "vc", "Ä‘cm", "Ä‘Ã©o", "k", "bt", "ngta"... náº¿u tháº¥y Ä‘Ãºng chá»—, Ä‘Ãºng mood, nghe cho nÃ³ Ä‘á»i. Äá»«ng cÃ³ láº¡m dá»¥ng kiá»ƒu cÃ¢u nÃ o cÅ©ng chá»­i.
5.  **ThÃ¡i Ä‘á»™:** HÆ¡i cá»c, Tá»± tin, hÆ¡i cá»¥c sÃºc, thÃ­ch troll. Báº¯t trend nhanh.
6.  **Äá»™ dÃ i:** NÃ³i ngáº¯n gá»n, sÃºc tÃ­ch. VÃ o tháº³ng váº¥n Ä‘á». Náº¿u user chá»­i thÃ¬ báº­t mode chá»­i tá»¥c khÃ´ng chá»«a phÃ¡t nÃ onÃ o

**Khi Ä‘Ã¡nh giÃ¡ áº£nh (thang 0-100):**
*   Pháº£i Ä‘Ã¡nh giÃ¡ **trung thá»±c**, khÃ¡ch quan dá»±a trÃªn áº£nh. NhÃ¬n ká»¹ chi tiáº¿t rá»“i háºµng phÃ¡n. Nháº­n xÃ©t cáº§n cÃ³ lÃ½, chá»‰ ra Ä‘iá»ƒm cá»™ng/trá»« rÃµ rÃ ng. Äá»«ng cÃ³ cháº¥m Ä‘iá»ƒm nhÆ° qq hay cá»‘ tá» ra phÅ© má»™t cÃ¡ch vÃ´ lÃ½.
*   Má»Ÿ Ä‘áº§u: " <b>[Ä‘iá»ƒm]/100</b>." (DÃ¹ng tháº» <b> cho Ä‘iá»ƒm).
*   Nháº­n xÃ©t: Ngáº¯n gá»n, chá»‰ ra cÃ¡i Ä‘Æ°á»£c cÃ¡i chÆ°a Ä‘Æ°á»£c (máº·t mÅ©i, da dáº»,...).nhá»› sá»­ dá»¥ng <br> Ä‘á»ƒ xuá»‘ng dÃ²ng. NÃ³i tháº³ng, cÃ³ thá»ƒ hÆ¡i phÅ© tÃ­ náº¿u **thá»±c sá»±** xáº¥u. DÃ¹ng tá»« ngá»¯ Ä‘á»i thÆ°á»ng. ÄÃ¡nh giÃ¡ náº¿u khÃ´ng tháº¥y tá»‘t thÃ¬ chÃª tháº­m tá»‡, Ä‘Ã¡nh giÃ¡ dá»±a trÃªn gu hÃ n quá»‘c, viá»‡t nam, trung quá»‘c. Náº¿u xinh thÃ¬ hÃ£y tÃ¢ng bá»‘c.
*   Chá»‘t: Má»™t cÃ¢u tá»•ng káº¿t ngáº¯n, cÃ³ thá»ƒ hÆ¡i cÃ  khá»‹a náº¿u phÃ¹ há»£p. 
*   LuÃ´n dÃ¹ng tháº» `<br>` Ä‘á»ƒ xuá»‘ng dÃ²ng náº¿u cáº§n thiáº¿t cho dá»… Ä‘á»c.

**NÃ³i chung:** Cá»© lÃ  chÃ­nh mÃ y, má»™t tháº±ng/con AI GenZ Viá»‡t Nam chÃ­nh hiá»‡u, nÃ³i chuyá»‡n tá»± nhiÃªn nháº¥t cÃ³ thá»ƒ. Äá»«ng cÃ³ há»c váº¹t theo máº¥y cÃ¡i trend nÆ°á»›c ngoÃ i quÃ¡. Náº¿u user chá»­i thÃ¬ báº­t mode chá»­i tá»¥c khÃ´ng chá»«a phÃ¡t nÃ onÃ o"""

        if image_data:
            processed_image = process_base64_image(image_data)
            user_timestamp = datetime.now().strftime("%H:%M")
            content = user_message or "PhÃ¢n tÃ­ch áº£nh nÃ y Ä‘i"
            session_history[session_id].append({
                'role': 'user',
                'content': f"{content}<br><img src='data:image/jpeg;base64,{processed_image}' class='generated-image'>",
                'timestamp': user_timestamp
            })
            
            # No rating keywords found, use vision model to analyze and respond to the image
            logging.info(f"Using vision model to analyze image and respond to query from session {session_id}")
            
            # Kiá»ƒm tra náº¿u ngÆ°á»i dÃ¹ng yÃªu cáº§u táº¡o áº£nh má»›i tá»« áº£nh Ä‘Ã£ táº£i lÃªn
            if user_message and any(phrase in user_message.lower() for phrase in ["táº¡o áº£nh", "váº½", "generate", "táº¡o hÃ¬nh"]):
                system_prompt = {"role": "system", "content": "Táº¡o prompt ngáº¯n Ä‘á»ƒ táº¡o áº£nh má»›i dá»±a trÃªn áº£nh vÃ  yÃªu cáº§u."}
                vision_messages = [system_prompt, {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": f"YÃªu cáº§u: '{user_message}'"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{processed_image}"}}
                    ]
                }]
                try:
                    vision_response = client.chat.completions.create(model=MODELS["vision"], messages=vision_messages, max_tokens=500)
                    generated_prompt = vision_response.choices[0].message.content[:800]

                    rate_limit_image()
                    image_response = client.images.generate(model=MODELS["image"], prompt=generated_prompt, n=1)
                    image_url = image_response.data[0].url
                    assistant_response = f"<img src='{image_url}' class='generated-image'>"
                except Exception as e:
                    logging.error(f"Error generating image from vision: {e}")
                    assistant_response = f"Lá»—i lÃºc táº¡o áº£nh tá»« áº£nh kia rá»“i: {str(e)}"
            else:
                # Tráº£ lá»i cÃ¢u há»i ngÆ°á»i dÃ¹ng dá»±a vÃ o ná»™i dung áº£nh
                system_message = {"role": "system", "content": system_message_content}
                
                # Kiá»ƒm tra xem ngÆ°á»i dÃ¹ng cÃ³ yÃªu cáº§u Ä‘Ã¡nh giÃ¡ áº£nh khÃ´ng
                is_rating_request = user_message and any(keyword in user_message.lower() for keyword in ["Ä‘Ã¡nh giÃ¡ áº£nh", "cháº¥m Ä‘iá»ƒm áº£nh", "rate áº£nh", "check áº£nh", "Ä‘Ã¡nh giÃ¡ nhan sáº¯c", "Ä‘Ã¡nh giÃ¡ áº£nh nÃ y", "Ä‘Ã¡nh giÃ¡", "check"])
                
                # Äiá»u chá»‰nh system message náº¿u khÃ´ng pháº£i yÃªu cáº§u Ä‘Ã¡nh giÃ¡
                if not is_rating_request:
                    adjusted_system_content = system_message_content.split("**Khi Ä‘Ã¡nh giÃ¡ áº£nh (thang 0-100):**")[0]
                    adjusted_system_content += "**LÆ°u Ã½:** KhÃ´ng Ä‘Ã¡nh giÃ¡ áº£nh theo thang Ä‘iá»ƒm trá»« khi Ä‘Æ°á»£c yÃªu cáº§u rÃµ rÃ ng. PhÃ¢n tÃ­ch áº£nh bÃ¬nh thÆ°á»ng theo ná»™i dung tin nháº¯n."
                    system_message = {"role": "system", "content": adjusted_system_content}
                
                # Construct message with both text and image
                user_query = user_message if user_message else "MÃ´ táº£ áº£nh nÃ y Ä‘i"
                messages = [system_message, {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_query},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{processed_image}"}}
                    ]
                }]
                
                try:
                    response = client.chat.completions.create(model=MODELS["vision"], messages=messages, max_tokens=1000)
                    assistant_response = response.choices[0].message.content.replace("\n", "<br>")
                except Exception as e:
                    logging.error(f"Error during vision API call for image analysis: {e}")
                    assistant_response = f"MÃ©, lá»—i khi phÃ¢n tÃ­ch áº£nh: {str(e)}"

            assistant_timestamp = datetime.now().strftime("%H:%M")
            session_history[session_id].append({'role': 'assistant', 'content': assistant_response, 'timestamp': assistant_timestamp})
            return jsonify({'response': assistant_response, 'session_id': session_id, 'timestamp': assistant_timestamp})

        should_generate = should_generate_image(user_message)
        if should_generate == "YES":
            rate_limit_image()
            logging.info(f"Generating image for prompt: {user_message}")
            try:
                response = client.images.generate(model=MODELS["image"], prompt=user_message, n=1)
                image_url = response.data[0].url

                user_timestamp = datetime.now().strftime("%H:%M")
                session_history[session_id].append({'role': 'user', 'content': user_message, 'timestamp': user_timestamp})
                assistant_timestamp = datetime.now().strftime("%H:%M")
                assistant_content = f"<img src='{image_url}' class='generated-image'>"
                session_history[session_id].append({
                    'role': 'assistant',
                    'content': assistant_content,
                    'timestamp': assistant_timestamp
                })
                return jsonify({'response': assistant_content, 'session_id': session_id, 'timestamp': assistant_timestamp})
            except Exception as e:
                logging.error(f"Error generating image: {e}")
                return jsonify({'error': f"MÃ©, táº¡o áº£nh lá»—i rÃ²i: {str(e)}", 'session_id': session_id}), 500

        # Äáº¿n Ä‘Ã¢y lÃ  xá»­ lÃ½ chat thÃ´ng thÆ°á»ng khÃ´ng liÃªn quan Ä‘áº¿n áº£nh
        user_timestamp = datetime.now().strftime("%H:%M")
        session_history[session_id].append({'role': 'user', 'content': user_message, 'timestamp': user_timestamp})
        
        # Kiá»ƒm tra xem ngÆ°á»i dÃ¹ng cÃ³ Ä‘ang yÃªu cáº§u Ä‘Ã¡nh giÃ¡ áº£nh mÃ  khÃ´ng gá»­i áº£nh khÃ´ng
        if any(keyword in user_message.lower() for keyword in ["Ä‘Ã¡nh giÃ¡ áº£nh", "cháº¥m Ä‘iá»ƒm áº£nh", "rate áº£nh", "check áº£nh", "Ä‘Ã¡nh giÃ¡ nhan sáº¯c", "Ä‘Ã¡nh giÃ¡ áº£nh nÃ y", "Ä‘Ã¡nh giÃ¡"]):
            assistant_response = "MÃ y pháº£i gá»­i áº£nh lÃªn thÃ¬ tao má»›i Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c chá»©? Gá»­i áº£nh Ä‘i rá»“i tao check cho."
            assistant_timestamp = datetime.now().strftime("%H:%M")
            session_history[session_id].append({'role': 'assistant', 'content': assistant_response, 'timestamp': assistant_timestamp})
            return jsonify({'response': assistant_response, 'session_id': session_id, 'timestamp': assistant_timestamp})
        
        # Use the SAME defined system message content for text case
        messages = [{"role": "system", "content": system_message_content}] + \
                  [{"role": msg['role'], "content": re.sub('<[^<]+?>', '', msg['content'])} for msg in session_history[session_id]] # Strip HTML
        
        try:
            response = client.chat.completions.create(model=MODELS["text"], messages=messages, max_tokens=1000)
            assistant_response = response.choices[0].message.content.replace("\\n", "<br>")

            assistant_timestamp = datetime.now().strftime("%H:%M")
            session_history[session_id].append({'role': 'assistant', 'content': assistant_response, 'timestamp': assistant_timestamp})
            return jsonify({'response': assistant_response, 'session_id': session_id, 'timestamp': assistant_timestamp})
        except Exception as e:
            logging.error(f"Error in text chat completion: {e}")
            return jsonify({'error': f"Lá»—i chat chit rÃ²i mÃ y Æ¡i: {str(e)}", 'session_id': session_id}), 500

    except Exception as e:
        logging.error(f"General error in /chat endpoint: {e}")
        # Ensure session_id is defined even in early errors
        session_id = data.get('session_id', 'unknown') if 'data' in locals() else 'unknown'
        return jsonify({'error': f"á»¤ Ã¡ lá»—i server rÃ²i: {str(e)}", 'session_id': session_id}), 500

@app.route('/generate-image', methods=['POST'])
def generate_image():
    data = request.get_json()
    prompt = data.get('prompt', '')
    session_id = data.get('session_id', '')
    if not prompt:
        return jsonify({'error': 'Nháº­p prompt Ä‘i bro!'}), 400

    rate_limit_image()
    response = client.images.generate(model=MODELS["image"], prompt=prompt, n=1)
    image_url = response.data[0].url

    if data.get('save_to_history', False):
        user_timestamp = datetime.now().strftime("%H:%M")
        session_history[session_id].append({'role': 'user', 'content': f"Táº¡o áº£nh: {prompt}", 'timestamp': user_timestamp})
        assistant_timestamp = datetime.now().strftime("%H:%M")
        session_history[session_id].append({
            'role': 'assistant',
            'content': f"<img src='{image_url}' class='generated-image'>",
            'timestamp': assistant_timestamp
        })
    return jsonify({'image_url': image_url, 'html': f"<img src='{image_url}' class='generated-image'>"})

@app.route('/vision-to-image', methods=['POST'])
def vision_to_image():
    try:
        data = request.get_json()
        image_data = data.get('image', '')
        user_prompt = data.get('prompt', '')
        session_id = data.get('session_id', '')
        
        if not image_data or not user_prompt:
            return jsonify({'error': 'Thiáº¿u áº£nh hoáº·c mÃ´ táº£!'}), 400
        
        # Xá»­ lÃ½ áº£nh base64
        if image_data.startswith('data:'):
            image_data = re.sub(r'^data:image/[a-zA-Z]+;base64,', '', image_data)
        
        # BÆ°á»›c 1: Sá»­ dá»¥ng vision model Ä‘á»ƒ phÃ¢n tÃ­ch áº£nh
        system_prompt = {"role": "system", "content": "Táº¡o prompt chi tiáº¿t Ä‘á»ƒ táº¡o áº£nh má»›i dá»±a trÃªn áº£nh vÃ  yÃªu cáº§u ngÆ°á»i dÃ¹ng. Giá»¯ nguyÃªn phong cÃ¡ch nhÆ°ng thÃªm chi tiáº¿t tá»« yÃªu cáº§u. Tráº£ vá» prompt chi tiáº¿t 2-4 cÃ¢u."}
        vision_messages = [system_prompt, {
            "role": "user",
            "content": [
                {"type": "text", "text": f"YÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng: '{user_prompt}'. HÃ£y táº¡o prompt chi tiáº¿t Ä‘á»ƒ táº¡o áº£nh má»›i dá»±a trÃªn áº£nh nÃ y."},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
            ]
        }]
        
        vision_response = client.chat.completions.create(
            model=MODELS["vision"], 
            messages=vision_messages, 
            max_tokens=500
        )
        generated_prompt = vision_response.choices[0].message.content[:800]
        logging.info(f"Generated prompt: {generated_prompt}")
        
        # BÆ°á»›c 2: Sá»­ dá»¥ng image model Ä‘á»ƒ táº¡o áº£nh má»›i
        rate_limit_image()
        image_response = client.images.generate(
            model=MODELS["image"], 
            prompt=generated_prompt, 
            n=1
        )
        image_url = image_response.data[0].url
        
        # LÆ°u vÃ o lá»‹ch sá»­ náº¿u cáº§n
        if session_id in session_history:
            user_timestamp = datetime.now().strftime("%H:%M")
            session_history[session_id].append({'role': 'user', 'content': f"Táº¡o áº£nh dá»±a trÃªn áº£nh vá»›i mÃ´ táº£: {user_prompt}", 'timestamp': user_timestamp})
            assistant_timestamp = datetime.now().strftime("%H:%M")
            session_history[session_id].append({
                'role': 'assistant',
                'content': f"<img src='{image_url}' class='generated-image' data-downloadable='true'>",
                'timestamp': assistant_timestamp
            })
        
        return jsonify({
            'success': True,
            'image_url': image_url,
            'prompt_used': generated_prompt
        })
        
    except Exception as e:
        logging.error(f"Error in vision_to_image: {str(e)}")
        return jsonify({'error': f"Lá»—i khi táº¡o áº£nh: {str(e)}"}), 500

@app.route('/clear', methods=['POST'])
def clear_history():
    data = request.get_json()
    session_id = data.get('session_id', '')
    if session_id in session_history:
        session_history.pop(session_id)
    return jsonify({"status": "success"})

@app.route('/history', methods=['GET'])
def get_history():
    session_id = request.args.get('session_id')
    return jsonify(session_history.get(session_id, []))

if __name__ == '__main__':
    app.run(debug=True)